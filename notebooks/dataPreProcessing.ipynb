{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 3259,
     "status": "ok",
     "timestamp": 1751941292116,
     "user": {
      "displayName": "Raam Prekash",
      "userId": "03210573549722720918"
     },
     "user_tz": -330
    },
    "id": "Svl84oghKiM4",
    "outputId": "a1be1149-b0d3-474f-f005-c185a310d441"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
     ]
    }
   ],
   "source": [
    "gitfrom google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "d4TnmlzvMamf"
   },
   "outputs": [],
   "source": [
    "!touch bert-sentiment-analysis/src/data_preprocessing.py\n",
    "!touch bert-sentiment-analysis/src/model.py\n",
    "!touch bert-sentiment-analysis/src/train.py\n",
    "!touch bert-sentiment-analysis/src/evaluate.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "FdOUE0NRMULG"
   },
   "outputs": [],
   "source": [
    "!mkdir -p bert-sentiment-analysis/data/raw\n",
    "!mkdir -p bert-sentiment-analysis/data/processed\n",
    "!mkdir -p bert-sentiment-analysis/notebooks\n",
    "!mkdir -p bert-sentiment-analysis/src"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "T7Uub12VuKtV"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv('/content/drive/MyDrive/bert-sentiment-analysis/data/raw/financial-data-sentiment-analysis.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 48,
     "status": "ok",
     "timestamp": 1751587191898,
     "user": {
      "displayName": "Raam Prekash",
      "userId": "03210573549722720918"
     },
     "user_tz": -330
    },
    "id": "hEzKWkeBu1jC",
    "outputId": "97d7d58f-2152-4ddd-9fa4-c512255ef68d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                            Sentence Sentiment\n",
      "0  The GeoSolutions technology will leverage Bene...  positive\n",
      "1  $ESI on lows, down $1.50 to $2.50 BK a real po...  negative\n",
      "2  For the last quarter of 2010 , Componenta 's n...  positive\n",
      "3  According to the Finnish-Russian Chamber of Co...   neutral\n",
      "4  The Swedish buyout firm has sold its remaining...   neutral\n"
     ]
    }
   ],
   "source": [
    "# Show first few rows\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 42,
     "status": "ok",
     "timestamp": 1751938755260,
     "user": {
      "displayName": "Raam Prekash",
      "userId": "03210573549722720918"
     },
     "user_tz": -330
    },
    "id": "P17tsM6LuuUA",
    "outputId": "0bc4dae1-09cd-47dc-bf06-b4c6b54d50d5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 5842 entries, 0 to 5841\n",
      "Data columns (total 2 columns):\n",
      " #   Column     Non-Null Count  Dtype \n",
      "---  ------     --------------  ----- \n",
      " 0   Sentence   5842 non-null   object\n",
      " 1   Sentiment  5842 non-null   object\n",
      "dtypes: object(2)\n",
      "memory usage: 91.4+ KB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# Show basic info\n",
    "print(df.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 33,
     "status": "ok",
     "timestamp": 1751587254176,
     "user": {
      "displayName": "Raam Prekash",
      "userId": "03210573549722720918"
     },
     "user_tz": -330
    },
    "id": "g11EJDDZu7R0",
    "outputId": "909f9c97-e45a-45ec-8720-d76c23195726"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentiment\n",
      "neutral     3130\n",
      "positive    1852\n",
      "negative     860\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Check label distribution\n",
    "print(df['Sentiment'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "MOztoTjx6j09"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "# Load CSV - Full Qualified Path\n",
    "df = pd.read_csv('/content/drive/MyDrive/bert-sentiment-analysis/data/raw/financial-data-sentiment-analysis.csv')\n",
    "\n",
    "def clean_text(text):\n",
    "\n",
    "    # Remove URLs\n",
    "    text = re.sub(r'http\\S+|www\\S+|https\\S+', '', text, flags=re.MULTILINE)\n",
    "\n",
    "    # Remove ticker symbols (e.g., $ESI)\n",
    "    text = re.sub(r'\\$\\w*', '', text)\n",
    "\n",
    "    # Remove special characters and numbers (optional, depending on use case)\n",
    "    text = re.sub(r'[^a-zA-Z\\s]', '', text)\n",
    "\n",
    "    # Remove extra whitespace\n",
    "    text = text.strip()\n",
    "\n",
    "    return text\n",
    "\n",
    "# Apply to your dataframe\n",
    "df['cleaned_sentence'] = df['Sentence'].apply(clean_text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 34,
     "status": "ok",
     "timestamp": 1751938768136,
     "user": {
      "displayName": "Raam Prekash",
      "userId": "03210573549722720918"
     },
     "user_tz": -330
    },
    "id": "q6IG0cPU2chE",
    "outputId": "caa55c74-81eb-4c67-c6d2-fa90a78e3eb2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label mapping: {'negative': np.int64(0), 'neutral': np.int64(1), 'positive': np.int64(2)}\n",
      "  Sentiment  label\n",
      "0  positive      2\n",
      "1  negative      0\n",
      "2  positive      2\n",
      "3   neutral      1\n",
      "4   neutral      1\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "import pandas as pd\n",
    "\n",
    "# Load CSV - Full Qualified Path\n",
    "df = pd.read_csv('/content/drive/MyDrive/bert-sentiment-analysis/data/raw/financial-data-sentiment-analysis.csv')\n",
    "\n",
    "# Initialize Label Encoder\n",
    "le = LabelEncoder()\n",
    "\n",
    "# Fit and transform the 'Sentiment' column to numeric labels\n",
    "df['label'] = le.fit_transform(df['Sentiment'])\n",
    "\n",
    "# Check the mapping\n",
    "label_mapping = dict(zip(le.classes_, le.transform(le.classes_)))\n",
    "print(\"Label mapping:\", label_mapping)\n",
    "\n",
    "# Check a few rows\n",
    "print(df[['Sentiment', 'label']].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 59,
     "status": "ok",
     "timestamp": 1751938764427,
     "user": {
      "displayName": "Raam Prekash",
      "userId": "03210573549722720918"
     },
     "user_tz": -330
    },
    "id": "utP1a1XX2_8l",
    "outputId": "799f9a1f-ba65-4b4e-89a9-af7340ec4d5b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train size: 4220\n",
      "Validation size: 745\n",
      "Test size: 877\n",
      "Train label distribution:\n",
      "label\n",
      "1    0.535782\n",
      "2    0.317062\n",
      "0    0.147156\n",
      "Name: proportion, dtype: float64\n",
      "Validation label distribution:\n",
      "label\n",
      "1    0.535570\n",
      "2    0.316779\n",
      "0    0.147651\n",
      "Name: proportion, dtype: float64\n",
      "Test label distribution:\n",
      "label\n",
      "1    0.535918\n",
      "2    0.316990\n",
      "0    0.147092\n",
      "Name: proportion, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "\n",
    "# Load CSV - Full Qualified Path\n",
    "df = pd.read_csv('/content/drive/MyDrive/bert-sentiment-analysis/data/raw/financial-data-sentiment-analysis.csv')\n",
    "\n",
    "# Ensure df has a 'label' column after encoding\n",
    "le = LabelEncoder()\n",
    "df['label'] = le.fit_transform(df['Sentiment'])\n",
    "\n",
    "# Step 1: Split off test set (e.g., 15% of data)\n",
    "train_val_df, test_df = train_test_split(\n",
    "    df,\n",
    "    test_size=0.15,\n",
    "    stratify=df['label'],  # maintain class proportions\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "# Step 2: Split train and validation sets (e.g., 85% train_val into 85% train, 15% validation)\n",
    "train_df, val_df = train_test_split(\n",
    "    train_val_df,\n",
    "    test_size=0.15,  # 15% of train_val is validation â†’ about 12.75% of total data\n",
    "    stratify=train_val_df['label'],\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "# Check the shape of splits\n",
    "print(f\"Train size: {train_df.shape[0]}\")\n",
    "print(f\"Validation size: {val_df.shape[0]}\")\n",
    "print(f\"Test size: {test_df.shape[0]}\")\n",
    "\n",
    "# Check label distribution in each set\n",
    "print(\"Train label distribution:\")\n",
    "print(train_df['label'].value_counts(normalize=True))\n",
    "print(\"Validation label distribution:\")\n",
    "print(val_df['label'].value_counts(normalize=True))\n",
    "print(\"Test label distribution:\")\n",
    "print(test_df['label'].value_counts(normalize=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 6434,
     "status": "ok",
     "timestamp": 1751937865280,
     "user": {
      "displayName": "Raam Prekash",
      "userId": "03210573549722720918"
     },
     "user_tz": -330
    },
    "id": "Fq4XMK9kiNPB",
    "outputId": "f7c52ef9-b278-46da-864b-16d0726e61d1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers in /usr/local/lib/python3.11/dist-packages (4.53.0)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from transformers) (3.18.0)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.30.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.33.1)\n",
      "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (2.0.2)\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (24.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from transformers) (6.0.2)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (2024.11.6)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from transformers) (2.32.3)\n",
      "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.21.2)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.5.3)\n",
      "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.11/dist-packages (from transformers) (4.67.1)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.30.0->transformers) (2025.3.2)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.30.0->transformers) (4.14.0)\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.30.0->transformers) (1.1.5)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.4.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2.4.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2025.6.15)\n"
     ]
    }
   ],
   "source": [
    "#Install Transformers\n",
    "!pip install transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 269,
     "referenced_widgets": [
      "ab514a12d0444566bd5b8ea0f6d4f821",
      "7b70aaea1f954a9ba44dc2af064b4c19",
      "d8159926ea594a088f867d37b84cc1f5",
      "e8f1635c0f5446ceb7086ac523128eb6",
      "772e06c50797411a9eedf85ad69dca03",
      "d5002916c9504637a43dc67a865fe9ef",
      "846e1f437eb446c1afd9a08451506b57",
      "bdf2655a2afd409aae36675fe2dec134",
      "ca7903b9a015468cbb4b4e9ce3e8b818",
      "10e8f977d8894e34b0c66028181a66eb",
      "12ca342236e2494cb0af902d2817f588",
      "d933488043af4dbeb9c2501d4801c61c",
      "f0c98a8346f54adca8f74dc68369009d",
      "cdea72fc908949689ba06fe9795b2fb9",
      "726f3ff01dff4a35a05ee915b84610c8",
      "acde1b8857eb4237bffc6ebacca72170",
      "96ad711284854e6888708b52a25d20cc",
      "b9de150f41494d6784bb575ebf2c1562",
      "d0709c11c16f4b4498d7e8f38523a5f6",
      "fc3e025c5ac4424d93c47da71bd8257e",
      "e62e723efe464bc5a23b3f9729ed4b3a",
      "a85be06811024b5793ed880ae3a4b5ed",
      "3965ea40e8da4b1294c948f5bdb57647",
      "7c178e96ce38469abcb3eedc29c92f41",
      "2c195e56c7c34f89b3ff46a71c7d4949",
      "268742b06b9140c899dd42361ff2b50e",
      "81cdf8a3707c48acb429c7890b9380b4",
      "67e51b012ee941c7b7dfef736ab5d041",
      "df7e3447a0a743f39cd72219299b7500",
      "4b9751854cb840f7bf5fa84d8b07e266",
      "87e1b1eb7e084e2bb2a9de13536a23e1",
      "4c763135616b44c989b95ae1557362de",
      "ede2d1d68a5b4f288f7fbc6b7e315ea5",
      "3c638e35abdd4a0c80beab0ee35e2d44",
      "d464bf4576c74a4bb65cae59b75350a0",
      "2b32777e0c4048e780b91c8bc0b0a8b6",
      "9f036b918d1e4a1992eb822e56e79a16",
      "93ef9a8c916b4e7f9e65a26a246d9f1c",
      "29757d9be4144922b6f1207e1c4ef77e",
      "62c6f44aa3bb484d9491e4268bb64cea",
      "22a74780ccb24172a66e56aa792675f5",
      "560ab1177c0c4525925e462e925a2e46",
      "bcb2cc86ae7542fc9f3379326bc3de7b",
      "4c638ee0f9694f76bceea6f099c811ef"
     ]
    },
    "executionInfo": {
     "elapsed": 31326,
     "status": "ok",
     "timestamp": 1751936440588,
     "user": {
      "displayName": "Raam Prekash",
      "userId": "03210573549722720918"
     },
     "user_tz": -330
    },
    "id": "lfdhCYWojAsn",
    "outputId": "80b010e0-5b85-4a5f-b775-29b3c81157ca"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
      "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
      "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
      "You will be able to reuse this secret in all of your notebooks.\n",
      "Please note that authentication is recommended but still optional to access public models or datasets.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ab514a12d0444566bd5b8ea0f6d4f821",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/48.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d933488043af4dbeb9c2501d4801c61c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3965ea40e8da4b1294c948f5bdb57647",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3c638e35abdd4a0c80beab0ee35e2d44",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/570 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Import and load the BERT tokenizer\n",
    "\n",
    "from transformers import BertTokenizer\n",
    "\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "QsMKNtUitMk2"
   },
   "outputs": [],
   "source": [
    "train_df['cleaned_sentence'] = train_df['Sentence'].apply(clean_text)\n",
    "val_df['cleaned_sentence'] = val_df['Sentence'].apply(clean_text)\n",
    "test_df['cleaned_sentence'] = test_df['Sentence'].apply(clean_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 9,
     "status": "ok",
     "timestamp": 1751939131823,
     "user": {
      "displayName": "Raam Prekash",
      "userId": "03210573549722720918"
     },
     "user_tz": -330
    },
    "id": "igMvG-_6tZ4N",
    "outputId": "d522054f-1d98-4f0c-b6e1-f43415fc0fd4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                               Sentence Sentiment  label  \\\n",
      "5294  Many of the commercial vessels had got stuck i...  negative      0   \n",
      "5735  potential defect with third-row seat belts. Te...  negative      0   \n",
      "2443  Excluding non-recurring items , pre-tax profit...  positive      2   \n",
      "1092  Profit before taxes was EUR 4.0 mn , down from...   neutral      1   \n",
      "1978  $SKH http://stks.co/163e Long setup. Watch for...  positive      2   \n",
      "\n",
      "                                       cleaned_sentence  \n",
      "5294  Many of the commercial vessels had got stuck i...  \n",
      "5735  potential defect with thirdrow seat belts Tesl...  \n",
      "2443  Excluding nonrecurring items  pretax profit su...  \n",
      "1092  Profit before taxes was EUR  mn  down from EUR...  \n",
      "1978  Long setup Watch for continuation and volume e...  \n"
     ]
    }
   ],
   "source": [
    "print(train_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 33,
     "status": "ok",
     "timestamp": 1751938829707,
     "user": {
      "displayName": "Raam Prekash",
      "userId": "03210573549722720918"
     },
     "user_tz": -330
    },
    "id": "g3aa92IasPfj",
    "outputId": "7c80eed3-64d9-40b4-ebfd-84748bd51d31"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "True\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "print('train_df' in globals())\n",
    "print('val_df' in globals())\n",
    "print('test_df' in globals())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 38,
     "status": "ok",
     "timestamp": 1751938851956,
     "user": {
      "displayName": "Raam Prekash",
      "userId": "03210573549722720918"
     },
     "user_tz": -330
    },
    "id": "c9h6C2jlsU4c",
    "outputId": "c738126b-124d-4028-daf0-37552808b12f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                               Sentence Sentiment  label\n",
      "5294  Many of the commercial vessels had got stuck i...  negative      0\n",
      "5735  potential defect with third-row seat belts. Te...  negative      0\n",
      "2443  Excluding non-recurring items , pre-tax profit...  positive      2\n",
      "1092  Profit before taxes was EUR 4.0 mn , down from...   neutral      1\n",
      "1978  $SKH http://stks.co/163e Long setup. Watch for...  positive      2\n",
      "                                               Sentence Sentiment  label\n",
      "3520                                         Long $PCLN  positive      2\n",
      "5147  $HLF shorts made a killing last couple days, m...  negative      0\n",
      "3843  Lee & Man Paper and Metso have a long and pros...  positive      2\n",
      "1398  Comparable operating profit for the quarter de...   neutral      1\n",
      "1976  The shipyard hopes the regional government in ...   neutral      1\n",
      "                                               Sentence Sentiment  label\n",
      "223   The number of bodily injury cases quadrupled i...  negative      0\n",
      "2609  Net sales decreased to EUR 91.6 mn from EUR 10...   neutral      1\n",
      "4277   $aapl high of day just hit. Back at it tomorrow.  positive      2\n",
      "2843  According to CEO Kai Telanne , the company 's ...  positive      2\n",
      "107   Finland 's dominating rail company VR is plann...   neutral      1\n"
     ]
    }
   ],
   "source": [
    "print(train_df.head())\n",
    "print(val_df.head())\n",
    "print(test_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "laOscDIEklfi"
   },
   "outputs": [],
   "source": [
    "'''\n",
    "Tokenize  Texts\n",
    "Tokenize 'cleaned_sentence' column in Train, Validation, and Test dataframes.\n",
    "'''\n",
    "def tokenize_texts(texts, max_length=128):\n",
    "    return tokenizer(\n",
    "        list(texts),                  # list of texts\n",
    "        padding='max_length',         # pad all to max_length\n",
    "        truncation=True,              # truncate longer texts\n",
    "        max_length=max_length,        # max token length\n",
    "        return_tensors='pt'           # PyTorch tensors\n",
    "    )\n",
    "\n",
    "train_encodings = tokenize_texts(train_df['cleaned_sentence'])\n",
    "val_encodings = tokenize_texts(val_df['cleaned_sentence'])\n",
    "test_encodings = tokenize_texts(test_df['cleaned_sentence'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Pu-1pXP41R5H"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "train_labels = torch.tensor(train_df['label'].values)\n",
    "val_labels = torch.tensor(val_df['label'].values)\n",
    "test_labels = torch.tensor(test_df['label'].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "y56yDyv61ZKB"
   },
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset\n",
    "\n",
    "class SentimentDataset(Dataset):\n",
    "    def __init__(self, encodings, labels):\n",
    "        self.encodings = encodings\n",
    "        self.labels = labels\n",
    "    def __getitem__(self, idx):\n",
    "        item = {key: val[idx] for key, val in self.encodings.items()}\n",
    "        item['labels'] = self.labels[idx]\n",
    "        return item\n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "\n",
    "train_dataset = SentimentDataset(train_encodings, train_labels)\n",
    "val_dataset = SentimentDataset(val_encodings, val_labels)\n",
    "test_dataset = SentimentDataset(test_encodings, test_labels)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Tmrb8De01RDG"
   },
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyMzkr0BYK07VlzcObBcv+Ah",
   "mount_file_id": "1t2tkyoZmT1GANp_5NiwHFNVr-GMi8OjC",
   "provenance": [
    {
     "file_id": "1x53SBAmQv0DIg12gStHfOqGBd3CVnBWl",
     "timestamp": 1751588013046
    },
    {
     "file_id": "1t2tkyoZmT1GANp_5NiwHFNVr-GMi8OjC",
     "timestamp": 1751587618990
    }
   ]
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
